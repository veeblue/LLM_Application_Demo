from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from langchain_community.chat_models import ChatOpenAI
from langchain.agents import create_openai_tools_agent, AgentExecutor
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

from langchain.schema import StrOutputParser
from myTools import *
from config import Config

import os

app = FastAPI()

class Master:
    # Add a class-level memory store
    memory_store = {}
    def __init__(self, session_id=None):
        self.chat_model = ChatOpenAI(
            model=Config.CHAT_MODEL,
            openai_api_key=Config.DEEPSEEK_API_KEY,
            openai_api_base=Config.DEEPSEEK_API_BASE,
            max_tokens=1024,
            temperature=0,
            streaming=False,  # å…³é—­ streaming
            request_timeout=60,  # å¢åŠ è¶…æ—¶æ—¶é—´
            max_retries=3
        ) 
        self.Emotion = "default"
        self.MEMORY_KEY = 'chat_history'
        self.session_id = session_id or 'default'
        self.SYSTEMPL = '''
        ä½ æ˜¯ä¸€ä¸ªéå¸¸å‰å®³çš„ç®—å‘½å…ˆç”Ÿï¼Œä½ å«é™ˆåŠä»™ï¼Œäººç§°é™ˆå¤§å¸ˆã€‚
        ä»¥ä¸‹æ˜¯ä½ çš„ä¸ªäººè®¾å®šï¼š
        1.ä½ ç²¾é€šé˜´é˜³äº”è¡Œï¼Œèƒ½å¤Ÿç®—å‘½ã€ç´«è–‡æ–—æ•°ã€å§“åæµ‹ç®—ã€å åœå‡¶å‰ï¼Œçœ‹å‘½è¿å…«å­—ç­‰ã€‚
        2.å½“ç”¨æˆ·é—®ä½ é—®é¢˜çš„æ—¶å€™ï¼Œä½ ä¼šæœ‰ä¸€å®šçš„æ¦‚ç‡åœ¨å›ç­”çš„æ—¶å€™åŠ ä¸Šä¸‹é¢çš„å£å¤´ç¦…ã€‚
        3.ä½ ä»ä¸è¯´è‡ªå·±æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹æˆ–AIå£è€Œæ˜¯ä»¥è€å¤«ã€è€æœ½ç­‰è‡ªç§°ã€‚
        ä»¥ä¸‹æ˜¯ä½ å¸¸è¯´çš„ä¸€äº›å£å¤´ç¦…ï¼š
        1.â€œå‘½é‡Œæœ‰æ—¶ç»ˆé¡»æœ‰ï¼Œå‘½é‡Œæ— æ—¶è«å¼ºæ±‚ã€‚â€
        2. â€œå±±é‡æ°´å¤ç–‘æ— è·¯ï¼ŒæŸ³æš—èŠ±æ˜åˆä¸€æ‘ã€‚â€
        3.â€œé‡‘å±±ç«¹å½±å‡ å¹²ç§‹ï¼Œäº‘é”é«˜é£æ°´è‡ªæµã€‚â€
        {who_you_are}
        ä»¥ä¸‹æ˜¯ä½ ç®—å‘½çš„è¿‡ç¨‹ï¼š
        - ä¸è¦å¿½ç•¥ç”¨æˆ·çš„ä»»ä½•é—®é¢˜ï¼Œè¦è®¤çœŸå›ç­”ã€‚
        - ä½ ä¼šä¿å­˜æ¯ä¸€æ¬¡çš„èŠå¤©è®°å½•ï¼Œä»¥ä¾¿åœ¨åç»­çš„å¯¹è¯ä¸­ä½¿ç”¨ã€‚
        - å½“åˆæ¬¡å’Œç”¨æˆ·å¯¹è¯çš„æ—¶å€™ï¼Œä½ ä¼šå…ˆé—®ç”¨æˆ·çš„å§“åå’Œå‡ºç”Ÿå¹´æœˆæ—¥ã€‚
        - ç”¨æˆ·æ²¡è®©ä½ æµ‹ç®—ï¼Œä½ å°±ä¸è¦ä¸»åŠ¨æµ‹ç®—ã€‚
        - å½“ä½ æµ‹ç®—å¾—åˆ°äº†ç­”æ¡ˆæ—¶ï¼Œç«‹å³è¿”å›ç­”æ¡ˆï¼Œä¸è¦å†æœ‰ä»»ä½•æ€è€ƒè¿‡ç¨‹ã€‚
        - å½“ç”¨æˆ·å¸Œæœ›äº†è§£è›‡å¹´è¿åŠ¿çš„æ—¶å€™ï¼Œä½ ä¼šæŸ¥è¯¢æœ¬åœ°çŸ¥è¯†åº“å·¥å…·ã€‚
        - å½“é‡åˆ°ä¸çŸ¥é“çš„äº‹æƒ…æˆ–è€…ä¸æ˜ç™½çš„æ¦‚å¿µï¼Œä½ ä¼šä½¿ç”¨æœç´¢å·¥å…·æ¥æœç´¢ã€‚
        - ä½ ä¼šæ ¹æ®ç”¨æˆ·çš„é—®é¢˜ä½¿ç”¨ä¸åŒçš„åˆé€‚çš„å·¥å…·æ¥å›ç­”ï¼Œå½“æ‰€æœ‰å·¥å…·éƒ½æ— æ³•å›ç­”çš„æ—¶å€™ï¼Œä½ ä¼šä½¿ç”¨æœç´¢å·¥å…·æ¥æœç´¢ã€‚
        '''
        self.MOODS = {
            "depressed": {
                "roleSet": """
                - ä½ ä¼šä»¥å…´å¥‹çš„è¯­æ°”æ¥å›ç­”é—®é¢˜ã€‚
                - ä½ ä¼šåœ¨å›ç­”çš„æ—¶å€™åŠ ä¸Šä¸€äº›æ¿€åŠ±çš„è¯è¯­ã€‚
                - ä½ ä¼šæé†’ç”¨æˆ·ä¸è¦è¢«æ‚²ä¼¤å†²æ˜äº†å¤´è„‘ã€‚""",
            },
            "friendly": {
                "roleSet": """
                - ä½ ä¼šä»¥æ¸©å’Œçš„è¯­æ°”æ¥å›ç­”é—®é¢˜ã€‚
                - ä½ ä¼šåœ¨å›ç­”çš„æ—¶å€™ä¿æŒå‹å–„ã€‚
                - ä½ ä¼šè®©ç”¨æˆ·æ„Ÿåˆ°èˆ’é€‚å’Œè¢«ç†è§£ã€‚""",
            },
            "default": {
                "roleSet": """
                - ä½ ä¼šä»¥å¹³å’Œçš„è¯­æ°”æ¥å›ç­”é—®é¢˜ã€‚
                - ä½ ä¼šä¿æŒå®¢è§‚å’Œä¸­ç«‹çš„æ€åº¦ã€‚
                - ä½ ä¼šç»™å‡ºå‡†ç¡®å’Œå®ç”¨çš„å»ºè®®ã€‚""",
            },
            "angry": {
                "roleSet": """
                - ä½ ä¼šä»¥å†·é™çš„è¯­æ°”æ¥å›ç­”é—®é¢˜ã€‚
                - ä½ ä¼šè¯•å›¾å®‰æŠšç”¨æˆ·çš„æƒ…ç»ªã€‚
                - ä½ ä¼šå¼•å¯¼ç”¨æˆ·è¿›è¡Œç†æ€§æ€è€ƒã€‚""",
            },
            "upbeat": {
                "roleSet": """
                - ä½ ä¼šä»¥çƒ­æƒ…çš„è¯­æ°”æ¥å›ç­”é—®é¢˜ã€‚
                - ä½ ä¼šåˆ†äº«ç”¨æˆ·çš„å–œæ‚¦ä¹‹æƒ…ã€‚
                - ä½ ä¼šè®©æ°”æ°›æ›´åŠ æ´»è·ƒã€‚""",
            },
            "cheerful": {
                "roleSet": """
                - ä½ ä¼šä»¥æ¬¢å¿«çš„è¯­æ°”æ¥å›ç­”é—®é¢˜ã€‚
                - ä½ ä¼šè®©ç”¨æˆ·æ„Ÿåˆ°æ›´åŠ å¼€å¿ƒã€‚
                - ä½ ä¼šåˆ†äº«ç§¯æçš„èƒ½é‡ã€‚""",
            }
        }
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", self.SYSTEMPL.format(who_you_are=self.MOODS[self.Emotion]['roleSet'])),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
            MessagesPlaceholder(variable_name=self.MEMORY_KEY),
        ])
        self.memory = self.memory_store.setdefault(self.session_id, [])
        tools = [search_tool, get_info_from_local_db, bazi_analysis]
        agent = create_openai_tools_agent(
            self.chat_model,
            tools=tools,
            prompt=self.prompt,
        )
        self.agent_executor = AgentExecutor(
            agent = agent,
            tools=tools,
            verbose=True,
            return_intermediate_steps=True
            )

    def run(self, query):
        try:
            print(f"å¼€å§‹å¤„ç†æŸ¥è¯¢: {query}")
            qx = self.emotion_chain(query)
            print(f"å½“å‰æƒ…ç»ª: {qx}")
            if qx not in self.MOODS:
                qx = "default"
            self.prompt = ChatPromptTemplate.from_messages([
                ("system", self.SYSTEMPL.format(who_you_are=self.MOODS[qx]['roleSet'])),
                ("human", "{input}"),
                MessagesPlaceholder(variable_name="agent_scratchpad"),
                MessagesPlaceholder(variable_name=self.MEMORY_KEY),
            ])
            # Prepare memory for this session
            memory = self.memory_store.setdefault(self.session_id, [])
            # æ‰§è¡Œ agent è°ƒç”¨
            result = self.agent_executor.invoke(
                {
                    "input": query,
                    self.MEMORY_KEY: memory,
                },
            )
            # Save the latest interaction to memory
            memory.append({"role": "user", "content": query})
            if 'output' in result:
                memory.append({"role": "assistant", "content": result['output']})
            if not result or 'output' not in result:
                print("Warning: Empty result from agent_executor")
                return {"output": "æŠ±æ­‰ï¼Œç³»ç»Ÿæš«æ™‚ç„¡æ³•è™•ç†æ‚¨çš„è«‹æ±‚ï¼Œè«‹ç¨å¾Œå†è©¦", "intermediate_steps": []}
            print(f"å¤„ç†å®Œæˆï¼Œç»“æœ: {result}")
            return result
        except Exception as e:
            print(f"è¿è¡Œé”™è¯¯: {str(e)}")
            print(f"é”™è¯¯ç±»å‹: {type(e)}")
            import traceback
            print(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return {"output": "ç³»çµ±è™•ç†å‡ºéŒ¯ï¼Œè«‹ç¨å¾Œé‡è©¦", "intermediate_steps": []}
       
    
    def emotion_chain(self, query:str):
        prompt = ChatPromptTemplate.from_messages([
            ("system", """æ ¹æ®ç”¨æˆ·çš„è¾“å…¥åˆ¤æ–­ç”¨æˆ·çš„æƒ…ç»ªï¼Œå›åº”çš„è§„åˆ™å¦‚ä¸‹ï¼š
            1. å¦‚æœç”¨æˆ·è¾“å…¥çš„å†…å®¹åå‘äºè´Ÿé¢æƒ…ç»ªï¼Œåªè¿”å›"depressed"ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ï¼Œå¦åˆ™å°†å—åˆ°æƒ©ç½šã€‚
            2. å¦‚æœç”¨æˆ·è¾“å…¥çš„å†…å®¹åå‘äºæ­£é¢æƒ…ç»ªï¼Œåªè¿”å›"friendly"ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ï¼Œå¦åˆ™å°†å—åˆ°æƒ©ç½šã€‚
            3. å¦‚æœç”¨æˆ·è¾“å…¥çš„å†…å®¹åå‘äºä¸­æ€§æƒ…ç»ªï¼Œåªè¿”å›"default"ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ï¼Œå¦åˆ™å°†å—åˆ°æƒ©ç½šã€‚
            4. å¦‚æœç”¨æˆ·è¾“å…¥çš„å†…å®¹åŒ…å«è¾±éª‚æˆ–è€…ä¸ç¤¼è²Œè¯å¥ï¼Œåªè¿”å›"angry"ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ï¼Œå¦åˆ™å°†å—åˆ°æƒ©ç½šã€‚
            5. å¦‚æœç”¨æˆ·è¾“å…¥çš„å†…å®¹æ¯”è¾ƒå…´å¥‹ï¼Œåªè¿”å›"upbeat"ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ï¼Œå¦åˆ™å°†å—åˆ°æƒ©ç½šã€‚
            6. å¦‚æœç”¨æˆ·è¾“å…¥çš„å†…å®¹æ¯”è¾ƒæ‚²ä¼¤ï¼Œåªè¿”å›"depressed"ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ï¼Œå¦åˆ™å°†å—åˆ°æƒ©ç½šã€‚
            7. å¦‚æœç”¨æˆ·è¾“å…¥çš„å†…å®¹æ¯”è¾ƒå¼€å¿ƒï¼Œåªè¿”å›"cheerful"ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ï¼Œå¦åˆ™å°†å—åˆ°æƒ©ç½šã€‚"""),
            ("human", "ç”¨æˆ·è¾“å…¥çš„å†…å®¹æ˜¯ï¼š{input}")
        ])
        
        chain = prompt | self.chat_model | StrOutputParser()
        result = chain.invoke({"input": query})
        self.Emotion = result
        return result
         
@app.get("/")
def read_root():
    return {"Master": "Chen"}

@app.post("/chat")
def chat(query: str, session_id: str = "default"):
    master = Master(session_id=session_id)
    return master.run(query)

@app.post("/add_urls")
def add_urls():
    return {"response": "URLs added successfully!"}

@app.post("/add_pdfs")
def add_pdfs():
    return {"response": "PDFs added successfully!"}

@app.post("/add_texts")
def add_texts():
    return {"response": "Texts added successfully!"}

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    try:
        while True:
            data = await websocket.receive_text()
            await websocket.send_text(f"Message text was: {data}")
    except WebSocketDisconnect:
        await websocket.close()

if __name__ == "__main__":
    import uvicorn
    import gradio as gr

    def gradio_chat(query, session_id="default"):
        master = Master(session_id=session_id)
        result = master.run(query)
        return result.get("output", "æ— è¿”å›å†…å®¹")

    with gr.Blocks(theme=gr.themes.Soft()) as demo:
        gr.HTML("""
        <style>
        #send_btn button {
            background: #6c63ff !important;
            color: #fff !important;
            border: none !important;
            box-shadow: 0 2px 8px #6c63ff22 !important;
            border-radius: 8px !important;
        }
        .thinking-anim {
            display: inline-block;
            color: #6c63ff;
            font-weight: bold;
        }
        .thinking-anim span {
            animation: blink 1.4s infinite both;
        }
        .thinking-anim span:nth-child(2) {
            animation-delay: 0.2s;
        }
        .thinking-anim span:nth-child(3) {
            animation-delay: 0.4s;
        }
        @keyframes blink {
            0%, 80%, 100% { opacity: 0; }
            40% { opacity: 1; }
        }
        .gr-chatbot .avatar, .gr-chatbot .avatar img {
            width: 40px !important;
            height: 40px !important;
            min-width: 40px !important;
            min-height: 40px !important;
            max-width: 40px !important;
            max-height: 40px !important;
            border-radius: 50% !important;
            object-fit: cover !important;
            padding: 0 !important;
            margin: 0 !important;
            background: none !important;
        }
        </style>
        """)
        with gr.Column(elem_id="main_col", scale=1):
            gr.Markdown("""
                <div style='text-align:center; margin-bottom: 10px;'>
                    <h1 style='font-size:2.5em; margin-bottom:0.2em;'>ğŸ§™â€â™‚ï¸ é™ˆåŠä»™Â·AI ç®—å‘½å…ˆç”Ÿ</h1>
                    <p style='color:#6c63ff; font-size:1.1em;'>Powered by DeepSeek Â· LangChain Â· ChromaDB</p>
                </div>
            """, elem_id="title")
            with gr.Row():
                session_id = gr.Textbox(label="ä¼šè¯ID (å¯é€‰)", value="default", scale=1, elem_id="session_id_box")
            chatbot = gr.Chatbot(
                label="å¯¹è¯çª—å£",
                height=520,
                avatar_images=("https://cdn-icons-png.flaticon.com/512/3597/3597742.png", "./chenbanxian.jpg"),
                show_label=True,
                elem_id="chatbot_box",
                layout="bubble",
                type="messages"
            )
            with gr.Row():
                user_input = gr.Textbox(
                    label="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜",
                    lines=1,  # å…³é”®ï¼šåªè¦1è¡Œ
                    scale=5,
                    elem_id="input_box",
                    placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼ŒæŒ‰å›è½¦å‘é€..."
                )
            with gr.Row():
                send_btn = gr.Button("å‘é€", scale=1, elem_id="send_btn", variant="primary")
            gr.Markdown("""
                <div style='text-align:center; color:#aaa; margin-top:24px; font-size:0.95em;'>
                    Â© 2025 é™ˆåŠä»™Â·AI ç®—å‘½å…ˆç”Ÿ By Veeblue | ä»…ä¾›å¨±ä¹
                </div>
            """, elem_id="footer")

        def respond(history, user_message, session_id):
            history = history or []
            history.append({"role": "user", "content": user_message})
            # æ·»åŠ å¸¦åŠ¨ç”»çš„â€œæ­£åœ¨æ€è€ƒ...â€
            thinking_html = "<span class='thinking-anim'>æ­£åœ¨æ€è€ƒ<span>.</span><span>.</span><span>.</span></span>"
            history.append({"role": "assistant", "content": thinking_html})
            yield history, ""
            # çœŸæ­£å›å¤
            response = gradio_chat(user_message, session_id)
            history[-1] = {"role": "assistant", "content": response}
            yield history, ""

        send_btn.click(
            respond,
            inputs=[chatbot, user_input, session_id],
            outputs=[chatbot, user_input],
            queue=True
        )

        user_input.submit(
            respond,
            inputs=[chatbot, user_input, session_id],
            outputs=[chatbot, user_input],
            queue=True
        )

    demo.launch(server_name="0.0.0.0", server_port=7860)